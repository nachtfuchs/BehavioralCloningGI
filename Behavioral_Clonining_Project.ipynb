{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioral Cloning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import successful.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.optimizers import Adam\n",
    "from time import time\n",
    "from random import randint\n",
    "\n",
    "%matplotlib inline\n",
    "print('Import successful.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and get an impression of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs created succesfully\n"
     ]
    }
   ],
   "source": [
    "source_path = 'data_middle/driving_log.csv'\n",
    "\n",
    "logs = []\n",
    "reader = csv.reader(open(source_path, 'rt'))\n",
    "for line in reader:\n",
    "    logs.append(line)\n",
    "\n",
    "print('logs created succesfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs.pop[0]:  ['center', 'left', 'right', 'steering', 'throttle', 'brake', 'speed']\n",
      "len(logs[0]):  7\n",
      "logs[0]:  ['IMG/center_2016_12_01_13_30_48_287.jpg', ' IMG/left_2016_12_01_13_30_48_287.jpg', ' IMG/right_2016_12_01_13_30_48_287.jpg', ' 0', ' 0', ' 0', ' 22.14829']\n",
      "logs[1][0]:  IMG/center_2016_12_01_13_30_48_404.jpg\n"
     ]
    }
   ],
   "source": [
    "# get rid of the first line that does not contain information about image paths and the corresponding information\n",
    "print('logs.pop[0]: ', logs.pop(0))\n",
    "print('len(logs[0]): ', len(logs[0]))\n",
    "print('logs[0]: ', logs[0])\n",
    "print('logs[1][0]: ', logs[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all the data in appropriate lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def resize_image(input_image):\n",
    "    '''@brief Reduce image size for computational reasons.\n",
    "    '''\n",
    "    x_size = 64 \n",
    "    y_size = 32\n",
    "    return cv2.resize(input_image, (x_size, y_size))\n",
    "\n",
    "def crop_image(input_image):\n",
    "    '''@brief Cut off the sky and lower part of the picture since it contains\n",
    "              little information about the track.\n",
    "    '''\n",
    "    offset_low = 40\n",
    "    offset_high = 140\n",
    "    return input_image[offset_low:offset_high]\n",
    "\n",
    "def change_color_space(input_image):\n",
    "    ''' Return image in S dimension of HSV color space\n",
    "    '''\n",
    "    return  cv2.cvtColor(input_image, cv2.COLOR_RGB2HSV)[:, :, 1]\n",
    "\n",
    "def image_wrapper(input_image):\n",
    "    '''@brief summarize all relevant image processing functions\n",
    "    '''\n",
    "    return change_color_space(resize_image(input_image))\n",
    "\n",
    "def img_load(path_to_table, steering_offset):\n",
    "    #read the path to the images\n",
    "    reader = csv.reader(open(path_to_table, 'rt'))\n",
    "    new_logs = []\n",
    "    for line in reader:\n",
    "        new_logs.append(line) #save the path in a list\n",
    "    #delete first line because it contains unnecessary information\n",
    "    new_logs.pop(0)\n",
    "    X = [] # empty list of \"images\"\n",
    "    y = [] # empty list of steering angles\n",
    "    folder = 'data/'\n",
    "    steeringThresh = 0.1 # Ignore images that have a steering angle below that threshold\n",
    "    counter = 0 # counts the accepted images\n",
    "    total_counter = 0 # counts all the images\n",
    "    for center, left, right, steering, throttle, brake, speed in new_logs:\n",
    "        total_counter += 1\n",
    "        # avoid importing data that have very small steering angles with a probability of 70%\n",
    "        if (float(steering) < steeringThresh) and (randint(0, 100) > 70):\n",
    "            counter += 1\n",
    "            # preprocess the images and save them in a list\n",
    "            X.append(image_wrapper(plt.imread(folder + center))) # include preprocessing\n",
    "            # append left and right images    \n",
    "            X.append(image_wrapper(plt.imread(folder + left[1:]))) # include preprocessing\n",
    "            X.append(image_wrapper(plt.imread(folder + right[1:]))) # include preprocessing\n",
    "\n",
    "            #get the steering angle\n",
    "            y.append(float(steering))\n",
    "            #add the steering offset to the left and right images\n",
    "            y.append(float(steering) + steering_offset)\n",
    "            y.append(float(steering) - steering_offset)\n",
    "        else: #accept all images that have a steering angle larger than the threshold\n",
    "            # preprocess the images and save them in a list\n",
    "            X.append(image_wrapper(plt.imread(folder + center))) # include preprocessing\n",
    "            # append left and right images    \n",
    "            X.append(image_wrapper(plt.imread(folder + left[1:]))) # include preprocessing\n",
    "            X.append(image_wrapper(plt.imread(folder + right[1:]))) # include preprocessing\n",
    "\n",
    "            #get the steering angle\n",
    "            y.append(float(steering))\n",
    "            #add the steering offset to the left and right images\n",
    "            y.append(float(steering) + steering_offset)\n",
    "            y.append(float(steering) - steering_offset)\n",
    "            \n",
    "    print('Neglected images [n]: ', total_counter - counter)\n",
    "    print('Neglected images [%]: ', (total_counter - counter) / total_counter)\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neglected images [n]:  6930\n",
      "Neglected images [%]:  0.7505686125852918\n",
      "Image loading time:  104.54295563697815 s\n",
      "len(X_train):  27699\n",
      "len(y_train):  27699\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "X_train, y_train = img_load(source_path, float(25/100))\n",
    "print('Image loading time: ', time() - start_time, 's')\n",
    "print('len(X_train): ', len(X_train))\n",
    "print('len(y_train): ', len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Flip images around the y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X_total):  55398\n",
      "len(y_total):  55398\n"
     ]
    }
   ],
   "source": [
    "#flip the images around the y-axis\n",
    "X_flipped = []\n",
    "y_flipped = []\n",
    "for X in X_train:\n",
    "    X_flipped.append(np.fliplr(X))\n",
    "# adjust the steering by changing the foresign\n",
    "for y in y_train:\n",
    "    y_flipped.append(-y)\n",
    "    \n",
    "# merge flipped data with original data\n",
    "X_total = X_train + X_flipped\n",
    "y_total = y_train + y_flipped\n",
    "\n",
    "print('len(X_total): ', len(X_total))\n",
    "print('len(y_total): ', len(y_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_np.shape:  (55398, 32, 64)\n",
      "y_np.shape:  (55398,)\n"
     ]
    }
   ],
   "source": [
    "X_np = np.array(X_total)\n",
    "y_np = np.array(y_total)\n",
    "print('X_np.shape: ', X_np.shape)\n",
    "print('y_np.shape: ', y_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_size:  (32, 64, 1)\n",
      "X_np[0]:  [[[255]\n",
      "  [ 64]\n",
      "  [ 43]\n",
      "  ..., \n",
      "  [ 96]\n",
      "  [ 95]\n",
      "  [ 95]]\n",
      "\n",
      " [[ 49]\n",
      "  [103]\n",
      "  [ 40]\n",
      "  ..., \n",
      "  [ 94]\n",
      "  [ 94]\n",
      "  [ 94]]\n",
      "\n",
      " [[230]\n",
      "  [152]\n",
      "  [ 47]\n",
      "  ..., \n",
      "  [ 92]\n",
      "  [ 92]\n",
      "  [ 92]]\n",
      "\n",
      " ..., \n",
      " [[ 30]\n",
      "  [ 31]\n",
      "  [ 27]\n",
      "  ..., \n",
      "  [ 81]\n",
      "  [ 81]\n",
      "  [ 80]]\n",
      "\n",
      " [[ 29]\n",
      "  [ 23]\n",
      "  [ 34]\n",
      "  ..., \n",
      "  [255]\n",
      "  [255]\n",
      "  [ 12]]\n",
      "\n",
      " [[ 40]\n",
      "  [ 36]\n",
      "  [ 32]\n",
      "  ..., \n",
      "  [ 71]\n",
      "  [ 35]\n",
      "  [ 38]]]\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the data\n",
    "X_np, y_np = shuffle(X_np, y_np)\n",
    "X_np = np.expand_dims(X_np, axis=3)\n",
    "image_size = np.shape(np.array(X_np[0]))\n",
    "print('image_size: ', image_size)\n",
    "print('X_np[0]: ', X_np[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now that the image preproccessing finished, the neural net needs to be defined in Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 32, 64, 1)     0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 27, 59, 3)     111         lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 9, 19, 3)      0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 7, 17, 3)      84          maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 2, 5, 3)       0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 2, 5, 3)       0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 30)            0           dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1)             31          flatten_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 226\n",
      "Trainable params: 226\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Lambda(lambda x: x/255.0 - 0.5,input_shape=(32, 64, 1)))\n",
    "\n",
    "model.add(Conv2D(3, 6, 6, border_mode='valid', activation='relu')) #introducing non-linearity\n",
    "model.add(MaxPooling2D((3,3), (3,3), 'valid'))\n",
    "model.add(Conv2D(3, 3, 3, border_mode='valid', activation='relu'))\n",
    "model.add(MaxPooling2D((3,3), (3,3), 'valid'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1)) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 44318 samples, validate on 11080 samples\n",
      "Epoch 1/5\n",
      "44318/44318 [==============================] - 119s - loss: 0.0479 - val_loss: 0.0345\n",
      "Epoch 2/5\n",
      "44318/44318 [==============================] - 121s - loss: 0.0375 - val_loss: 0.0311\n",
      "Epoch 3/5\n",
      "44318/44318 [==============================] - 130s - loss: 0.0350 - val_loss: 0.0304\n",
      "Epoch 4/5\n",
      "44318/44318 [==============================] - 129s - loss: 0.0335 - val_loss: 0.0292\n",
      "Epoch 5/5\n",
      "44318/44318 [==============================] - 153s - loss: 0.0326 - val_loss: 0.0289\n",
      "Total training time:  654.0578637123108\n"
     ]
    }
   ],
   "source": [
    "# keras model compile, choose optimizer and loss func\n",
    "start_time = time()\n",
    "# train the model\n",
    "model.compile(loss = 'mse', optimizer = 'adam')\n",
    "model.fit(x = X_np, y = y_np, validation_split = 0.2, shuffle = False, nb_epoch=5) #data is shuffled above\n",
    "print('Total training time: ', time() - start_time)\n",
    "model.save('model_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
